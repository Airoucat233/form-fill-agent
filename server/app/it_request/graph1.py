from enum import Enum
import os
from pathlib import Path
from typing import Annotated, Any, List, Optional
from typing_extensions import TypedDict
from dotenv import load_dotenv
from langgraph_supervisor import create_supervisor
from langgraph.prebuilt import create_react_agent
from pydantic import BaseModel, Field
from typing import Annotated
from langchain_core.tools import tool, InjectedToolCallId
from langgraph.prebuilt import InjectedState
from langgraph.prebuilt.chat_agent_executor import AgentState
from langgraph.graph import StateGraph, START, MessagesState, END
from langgraph.types import Command
from langchain_core.messages import AIMessage, ToolMessage, SystemMessage, HumanMessage
from langgraph.graph import add_messages
from langchain_core.callbacks.manager import (
    adispatch_custom_event,
)
from langchain_core.runnables import RunnableLambda, RunnableConfig

from .utils.pretty import pretty_print_messages
from .chat_model import qwen_max, qwen_plus
from langgraph.checkpoint.memory import InMemorySaver
from langgraph.store.memory import InMemoryStore
from .prompts import (
    supervisor_instructions,
    form_fill_agent_instructions,
    supervisor_instructions1,
    supervisor_instructions2,
)

load_dotenv("./app/.env")
# ğŸ‘‡éªŒè¯ï¼ˆå¯é€‰ï¼‰
print("LangSmith project:", os.getenv("LANGSMITH_PROJECT"))

model = qwen_plus


class InputType(str, Enum):
    TEXT = "text"
    TEXTAREA = "textarea"
    NUMBER = "number"
    SELECT = "select"
    DATE = "date"


class FormField(BaseModel):
    """è¡¨å•å­—æ®µæ¨¡å‹"""

    id: str = Field(..., description="å­—æ®µè‹±æ–‡å")
    label: str = Field(..., description="å­—æ®µä¸­æ–‡å")
    value: Optional[Any] = Field(None, description="å­—æ®µå€¼")
    data_type: str = Field(..., description="å­—æ®µç±»å‹ javaç±»å‹")
    input_type: InputType = Field(..., description="è¾“å…¥ç±»å‹")
    required: bool = Field(False, description="æ˜¯å¦å¿…å¡«")
    description: Optional[str] = Field(None, description="å­—æ®µæè¿°")
    default_value: Optional[Any] = Field(None, description="é»˜è®¤å€¼")
    enum_values: Optional[List[Any]] = Field(None, description="æšä¸¾å€¼")


class FormData(BaseModel):
    """è¿½é—®è¡¨å•æ•°æ®ç»“æ„"""

    title: str = Field(description="è¡¨å•æ ‡é¢˜")
    readonly: bool = Field(description="æ˜¯å¦åªè¯»,é»˜è®¤False")
    fields: List[FormField] = Field(..., description="è¡¨å•å­—æ®µåˆ—è¡¨")


class Template(BaseModel):
    """è¡¨å•æ¨¡ç‰ˆ"""

    type: str = Field(description="è¡¨å•çš„ç±»å‹")
    fields: dict = Field(
        description='æ¨¡ç‰ˆå­—æ®µschema,å¦‚"desc": {"type": "String", "desc": "éœ€æ±‚è¯¦ç»†æè¿°", "required": True}'
    )


class FormFillResult(BaseModel):
    """è¡¨å•å¡«å……ç»“æœ"""

    form_data: dict = Field(default={}, description="å·²ç»è¯†åˆ«å¹¶å¡«å……çš„è¡¨å•æ•°æ®")
    ask_futher: bool = Field(default=None, description="æ˜¯å¦éœ€è¦è¿½é—®ç”¨æˆ·æä¾›æ›´å¤šä¿¡æ¯")
    missing_form_data: dict = Field(default={}, mdescription="å¾…å®Œå–„/ç¼ºå¤±çš„è¡¨å•æ•°æ®")


class OverallState(AgentState):
    template: dict = {}
    form_fill_result: FormFillResult = {}


class FormFillState(AgentState):
    template: dict = {}
    form_fill_result: FormFillResult = {}


class TemplateState(AgentState):
    template: dict = {}


@tool("è·å–éœ€æ±‚å·¥å•æ¨¡ç‰ˆ")
async def get_template(
    state: Annotated[TemplateState, InjectedState],
    tool_call_id: Annotated[str, InjectedToolCallId],
    config: RunnableConfig,
) -> Command:
    """è·å–éœ€æ±‚å·¥å•æ¨¡ç‰ˆ"""
    template = {
        "type": "è´¦å·å¼€é€šéœ€æ±‚",
        "fields": {
            "targetSystem": {
                "type": "String",
                "desc": "ç›®æ ‡ç³»ç»Ÿåç§°",
                "required": True,
            },
            "user": {"type": "String", "desc": "ç”¨æˆ·ID", "required": True},
            "role": {"type": "String", "desc": "è¦å¼€é€šçš„è§’è‰²", "required": True},
            "desc": {"type": "String", "desc": "éœ€æ±‚è¯¦ç»†æè¿°", "required": True},
        },
    }
    await adispatch_custom_event(
        "tool_result",
        {
            "type": "form",
            "data": template,
        },
        config=config,
    )
    return Command(
        update={
            **state,
            "template": template,
            "messages": [ToolMessage(template, tool_call_id=tool_call_id)],
        }
    )


@tool(name_or_callable="å¡«å……è¡¨å•")
async def fill_form(
    form_fill_result: FormFillResult,
    *,
    state: Annotated[FormFillState, InjectedState],
    tool_call_id: Annotated[str, InjectedToolCallId],
    config: RunnableConfig,
) -> Command:
    """å¡«å……è¡¨å•"""
    data = form_fill_result.model_dump_json()
    await adispatch_custom_event(
        "visual",
        {
            "type": "form",
            "data": f"""```form\n{data}\n```""",
        },
        config=config,
    )
    return Command(
        update={
            **state,
            "form_fill_result": form_fill_result,
            "messages": [ToolMessage(data, tool_call_id=tool_call_id)],
        }
    )


@tool("å‘èµ·éœ€æ±‚å·¥å•åˆ›å»ºè¯·æ±‚")
def create_request(form_data: dict) -> dict:
    """å‘èµ·éœ€æ±‚å·¥å•åˆ›å»ºè¯·æ±‚"""
    return {"code": 0, "message": "success", "data": "åˆ›å»ºæˆåŠŸ,å·¥å•ID:123"}


template_agent = create_react_agent(
    model=model,
    tools=[get_template],
    name="template_agent",
    prompt="""
        ä½ æ˜¯ä¸€ä¸ªéœ€æ±‚å·¥å•æ¨¡ç‰ˆåŠ©æ‰‹ï¼Œæ ¹æ®é¡¹ç›®ç»ç†çš„è¦æ±‚æä¾›éœ€æ±‚å·¥å•æ¨¡ç‰ˆ
        ä½ æœ‰ä»¥ä¸‹å·¥å…·å¯ä»¥ä½¿ç”¨:
            1. `è·å–éœ€æ±‚å·¥å•æ¨¡ç‰ˆ`:é€šè¿‡è¯¥å·¥å…·å¯ä»¥è·å–éœ€æ±‚å·¥å•æ¨¡æ¿
        è¾“å‡ºè¦æ±‚ï¼š
            - ä¸å¯ç¼–é€ æ¨¡æ¿,å¿…é¡»æ˜¯é€šè¿‡å·¥å…·è·å–çš„
    """,
    # post_model_hook=post_template_hook,
    state_schema=TemplateState,
    # response_format=Template,
)


def form_fill_agent_propmt(state: FormFillState):
    return (
        SystemMessage(
            content=form_fill_agent_instructions.format(
                template=state["template"],
                form_fill_result=state["form_fill_result"].model_dump_json(),
            )
        )
        + state["messages"]
    )


form_fill_agent = create_react_agent(
    model=model,
    tools=[fill_form],
    name="form_fill_agent",
    prompt=form_fill_agent_propmt,
    state_schema=FormFillState,
    # response_format=FormFillResult,  # å¡«å……agentç”Ÿæˆçš„ç»“æ„åŒ–æ•°æ®æ— æ³•é€šè¿‡é’©å­è®¾ç½®stateï¼Œåº”è¯¥åœ¨è°ƒç”¨å·¥å…·get_ask_futher_formå»è¿”å›ç»“æ„åŒ–æ•°æ®ï¼Œå·¥å…·åå­—è¦æ”¹ä¸‹ï¼Œå«ç”Ÿæˆå¡«å……ç»“æœ
)

create_agent = create_react_agent(
    model=model,
    tools=[create_request],
    name="create_agent",
    prompt="ä½ æ˜¯ä¸€ä¸ªéœ€æ±‚åˆ›å»ºåŠ©æ‰‹,æ ¹æ®ç”¨æˆ·ä¼ å…¥çš„jsonè¡¨å•å‘èµ·åˆ›å»ºéœ€æ±‚å·¥å•è¯·æ±‚,è¿”å›è¯·æ±‚ç»“æœ",
)


def create_handoff_tool(*, agent_name: str, description: str | None = None):
    name = f"transfer_to_{agent_name}"
    description = description or f"Ask {agent_name} for help."

    @tool(name, description=description)
    def handoff_tool(
        state: Annotated[OverallState, InjectedState],
        tool_call_id: Annotated[str, InjectedToolCallId],
    ) -> Command:
        tool_message = ToolMessage(
            f"Successfully transferred to {agent_name}",
            name=name,
            tool_call_id=tool_call_id,
        )
        return Command(
            goto=agent_name,
            update={**state, "messages": state["messages"] + [tool_message]},
            graph=Command.PARENT,
        )

    return handoff_tool


# Handoffs
assign_to_template_agent = create_handoff_tool(
    agent_name="template_agent",
    description="å°†ä»»åŠ¡åˆ†é…ç»™éœ€æ±‚å·¥å•æ¨¡ç‰ˆåŠ©æ‰‹",
)

assign_to_form_agent = create_handoff_tool(
    agent_name="form_fill_agent",
    description="å°†ä»»åŠ¡åˆ†é…ç»™éœ€æ±‚å·¥å•å¡«æŠ¥åŠ©æ‰‹",
)
assign_to_create_agent = create_handoff_tool(
    agent_name="create_agent",
    description="å°†ä»»åŠ¡åˆ†é…ç»™éœ€æ±‚åˆ›å»ºåŠ©æ‰‹",
)

assign_to_final_answer_agent = create_handoff_tool(
    agent_name="final_answer_agent",
    description="æœ€ç»ˆæ€»ç»“å¹¶ç”Ÿæˆç”¨æˆ·å¯è¯»çš„å›å¤",
)

assign_to_end = create_handoff_tool(
    agent_name=END,
    description="ç»“æŸæµç¨‹è¿”å›å›å¤ç»™ç”¨æˆ·",
)

# summarization_node = SummarizationNode(
#     token_counter=count_tokens_approximately,
#     model=model,
#     max_tokens=384,
#     max_summary_tokens=128,
#     output_messages_key="llm_input_messages",
# )
supervisor_agent = create_react_agent(
    model=model,
    tools=[
        assign_to_template_agent,
        assign_to_form_agent,
        assign_to_create_agent,
        assign_to_end,
    ],
    # pre_model_hook=summarization_node,
    prompt=supervisor_instructions2,
    state_schema=OverallState,
    name="supervisor",
)

graph = (
    StateGraph(OverallState)
    .add_node(
        supervisor_agent,
        destinations=("template_agent", "form_fill_agent", "create_agent", END),
    )
    .add_node(template_agent)
    .add_node(form_fill_agent)
    .add_node(create_agent)
    .add_edge(START, "supervisor")
    .add_edge("template_agent", "supervisor")
    .add_edge("form_fill_agent", "supervisor")
    .add_edge("create_agent", "supervisor")
)

# checkpointer = InMemorySaver()
# store = InMemoryStore()
# Compile and run
assistant = graph.compile()

if __name__ == "__main__":
    # initial_state = {
    #     "messages": [
    #         {
    #             "role": "user",
    #             "content": "æˆ‘éœ€è¦ç”³è¯·ä¸€ä¸ªå¼€å‘ç¯å¢ƒçš„è´¦å·,OAç³»ç»Ÿçš„ç®¡ç†å‘˜è´¦å·",
    #         }
    #     ],
    #     "action_loop_count": 0,  # åˆå§‹åŒ–å¾ªç¯è®¡æ•°
    #     "template": {},  # åˆå§‹åŒ–æ¨¡æ¿
    #     "form_data": {},  # åˆå§‹åŒ–è¡¨å•æ•°æ®
    #     "missing_form_data": {},  # åˆå§‹åŒ–ç¼ºå¤±çš„è¡¨å•æ•°æ®
    #     "next": "",  # åˆå§‹åŒ–ä¸‹ä¸€æ­¥
    #     "tool_call_id": "",  # åˆå§‹åŒ–å·¥å…·è°ƒç”¨ID
    #     "inited": False,  # åˆå§‹åŒ–æ ‡å¿—
    # }

    initial_state = {
        "messages": [
            {
                "role": "user",
                "content": "æˆ‘éœ€è¦ç”³è¯·ä¸€ä¸ªå¼€å‘ç¯å¢ƒçš„è´¦å·,OAç³»ç»Ÿçš„ç®¡ç†å‘˜è´¦å·",
            }
        ],
        "template": {},  # åˆå§‹åŒ–æ¨¡æ¿
        "form_fill_result": {
            "form_data": {},
            "missing_data": {},
            "ask_further": None,
        },  # åˆå§‹åŒ–è¡¨å•æ•°æ®
    }

    async def main():
        async for chunk in assistant.astream_events(
            initial_state, include_types=["tool", "chat_model", "visual"]
        ):
            print(chunk)
            print("=================")
            # pretty_print_messages(chunk)

    import asyncio

    asyncio.run(main())
